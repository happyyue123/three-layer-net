# 模型介绍
本研究使用了一个三层全连接神经网络 (ThreeLayerNet)，用于分类任务。以下是模型的主要特征和结构说明：

输入层尺寸：784，对应于处理 28x28 像素的手写数字图片。
第一隐藏层：包含 128 个神经元。
第二隐藏层：包含 36 个神经元。
输出层尺寸：10，表示有 10 个类别的输出，这对应于十个数字（0到9）的分类任务。
激活函数：虽然代码中没有直接说明使用的激活函数，通常全连接层会配合非线性激活函数如 ReLU 使用。
损失函数：未明确指定，但通常在这类任务中使用交叉熵损失函数。
正则化：使用 L2 正则化，正则化强度为 0.001，有助于防止模型过拟合。
# 数据集介绍
使用的是 MNIST 数据集，它是一个广泛使用的手写数字识别数据集：

数据集特点：包含 70,000 张灰度的手写数字图片，分为 60,000 张训练图片和 10,000 张测试图片。
图片尺寸：每张图片为 28x28 像素，通常在输入神经网络前被展平为 784 个特征的一维数组。

# 实验设置
实验中，模型通过随机梯度下降法进行训练，具体的训练参数如下：

迭代次数：3000，足以让模型在训练数据上充分学习。
批量大小：1000，指每次迭代随机选择 1000 个样本进行训练。

为了确定最优的网络参数配置，我们进行了一系列的实验，其中包括不同的隐藏层大小、学习率和正则化强度的组合。下面是实验的详细设置和结果分析：

## 实验设计
实验涉及到以下几个参数的变体：

第一隐藏层神经元数：考虑了两种设置 [128, 256]。
第二隐藏层神经元数：设置为 [20, 36, 78]。
学习率：尝试了四个不同的级别 [1e-4, 1e-2, 1e-0, 1e2]。
正则化强度：包括四种强度 [0, 1e-5, 1e-3, 1e-1]。
这些参数的组合导致了一系列的配置，每种配置都进行了独立的训练和验证，以评估其性能。

## 实验过程
对于每一种参数组合，我们都进行了以下步骤：

1. 模型初始化：根据每一组参数初始化模型。
2. 训练过程：使用交叉熵损失函数，通过随机梯度下降法训练模型。
3. 性能评估：在独立的验证集上评估模型，记录损失和准确率。

## 结果分析
通过系统地变化参数并记录每一组合的性能，我们能够观察到以下趋势：

1. 隐藏层大小：较大的隐藏层通常提供了更好的模型容量，从而在复杂任务上表现更佳，但也容易引起过拟合，尤其是在正则化较弱时。
2. 学习率：适中的学习率（如 1e-2）在大多数情况下能够有效平衡收敛速度和稳定性。过高或过低的学习率都会导致性能下降，特别是极端值如 1e0 和 1e2。
3. 正则化强度：一定程度的正则化（如 1e-3）有助于改善模型在验证集上的泛化能力，而完全没有正则化（0）或过强的正则化（1e-1）则可能导致性能不佳。


## 最终选择参数为：
第一隐藏层：包含128个神经元
第二隐藏层：包含36个神经元
学习率：初始学习率设定为 0.01。
学习率衰减：学习率按每次迭代后的 0.95 衰减，有助于在训练后期稳定学习过程。
正则化：L2 正则化强度为 0.001。